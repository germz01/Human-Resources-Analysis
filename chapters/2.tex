\section{Clustering Analysis by K-means} % (fold)
\label{sec:clustering_analysis_by_k_means}
In questa prima sezione del capitolo relativo al Clustering, ci occupiamo di rilevare ,attraverso l'applicazione
dell'algoritmo \textit{K-means}, i gruppi di dipendenti con caratteristiche comuni all'interno del data set.
La nostra analisi è stata inizialmente svolta sul data set completo, utilizzando però solo alcune variabili tra
quelle a disposizione, come verrà spiegato nelle sezioni successive. Per questa analisi globale vengono
inoltre fornite alcune statistiche, per meglio integrare le informazioni ottenute dal clustering. Come già
specificato nella Sezione \ref{sec:variable_transformations}, i valori delle variabili discrete sono stati
normalizzati in un intervallo compreso tra $0$ e $1$, al fine di rendere più agevole il confronto in fase di
clustering. Inoltre, per ottenere un risultato più pulito sono stati rimossi gli outliers ($1282$ records)
presenti nella variabile \textit{Time Spend Company}, come evidenziato nella Sezione
\ref{sec:assessing_data_quality}. Infine, come ulteriori casi di studio, sono riportate anche le analisi
relative alla sola porzione del data set contenente gli impiegati che hanno lasciato l'azienda e a quella invece
contenente gli impiegati ancora al suo interno.
\subsection{Choice of attributes and distance function} % (fold)
\label{sub:choice_of_attributes_and_distance_function}
% \begin{figure}[b!]
%   \centering
%   \includegraphics[width=\textwidth, height=10cm]{images/kmeans/SSE.pdf}
%   \caption{Prova}
%   \label{fig:sse}
% \end{figure}
Le \textit{variabili} sulle quali abbiamo deciso di applicare l'analisi tramite K-means sono un sottoinsieme di
quelle a disposizione nel data set, in particolare, sono le variabili di tipo continuo
\textit{Satisfaction Level} e \textit{Latest Evaluation}, e le variabili di tipo discreto
\textit{Number Project}, \textit{Average Montly Hours} e \textit{Time Spend Company}. Sono state escluse le
variabili binarie. Vista la natura delle variabili utilizzate nell'applicazione dell'algoritmo, la distance
function da noi utilizzata per quantificare la distanza tra due data objects è la \textit{distanza Euclidea},
rappresentata dalla nota formula
\begin{equation*}
    dist(p,\ q) \ = \ \sqrt{\sum_{i = 0}^{k}(q_i - p_i)^2}\quad,
\end{equation*}
dove con $q_i$ e $p_i$ vengono rappresentati li i-esimi attributi dei data objects $p$ e $q$.
% subsection choice_of_attributes_and_distance_function (end)
\subsection{Identification of the best value of k} % (fold)
\label{sub:identification_of_the_best_value_of_k}
Al fine di identificare il miglior numero $k$ di clusters da utilizzare, abbiamo tenuto conto dell'
\textit{Error Sum of Squares} (SSE), ossia della somma, elevata al quadrato, della distanza tra ogni singolo data object e il centroide più vicino, ottenuta mediante la formula
\begin{equation*}
    SSE \ = \ \sum_{i = 1}^{K} \sum_{x \in C_i} dist(c_i,\ x)^2 \quad ,
\end{equation*}
dove \textit{dist} rappresenta la distanza Euclidea tra il centroide $c_i$ ed il data object $x$.
 A partire da un valore iniziale di $k$ pari a $2$ fino ad un valore
massimo di $50$ abbiamo calcolato l'SSE risultante dall'applicazione dell'algoritmo come possiamo osservare in
Figura \ref{fig:sse}, e abbiamo infine deciso per un valore di $k$ pari a $4$ per l'applicazione di K-means sul
data set totale.
% subsection identification_of_the_best_value_of_k (end)
\subsection{Characterization of the obtained clusters } % (fold)
\label{sub:characterization_of_the_obtained_clusters}
Andiamo adesso a dare una descrizione dei cluster emersi dall'applicazione dell'algoritmo K-means con i parametri
che abbiamo deciso di utilizzare. Cominciando con l'osservare lo scatterplot relativo ai cluster degli impiegati
che hanno lasciato l'azienda, Figura , notiamo che sono ben visibili $3$ categorie distinte di impiegati, che
possiamo descrivere discorsivamente come
\begin{itemize}
    \item Impiegati con un livello di soddisfazione basso e un alto score nella valutazione. Questo cluster ci
    suggerisce la motivazione per cui questi impiegati hanno lasciato l'azienda, ossia una quantità troppo elevata
    di ore di lavoro, dalla quale deriva probabilmente l'alto score nella valutazione.
    \item Impiegati con un basso livello di soddisfazione, compreso tra $0.3$ e $0.5$, e un altrettanto basso score
    nella valutazione, compreso tra $0.2$ e $0.55$. La scarsa produttività e soddisfazione suggeriscono che questo
    gruppo di impiegati ha deciso di lasciare l'azienda per insoddisfazione verso la posizione lavorativa offerta.
    \item Impiegati con un alto livello di soddisfazione e un alto score nella valutazione, che probabilmente hanno
    lasciato l'azienda dopo aver ricevuto un'offerta di lavoro più vantaggiosa.
\end{itemize}
\lipsum
\begin{figure}[t]
    \begin{center}
        \subcaptionbox{\label{fig:cluster_left}}{\includegraphics[scale=0.45]{images/kmeans/cluster_left.pdf}}
        \subcaptionbox{\label{fig:cluster_stayed}}{\includegraphics[scale=0.45]{images/kmeans/cluster_stayed.pdf}}
        \caption{Nella Figura \ref{fig:cluster_left} troviamo i cluster emersi dall'analisi dei dipendenti che
        hanno lasciato l'azienda, nella Figura \ref{fig:cluster_stayed} troviamo invece quelli emersi dall'analisi
        dei dipendenti rimasti nell'azienda.}
    \end{center}
\end{figure}
% subsection characterization_of_the_obtained_clusters (end)
% section clustering_analysis_by_k_means (end)


\newpage
\section{Hierarchical clustering}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{../images/hierarchical/dendrogram_average_euclidean.pdf}
  \caption{Dendrogramma per method X e metrica Y}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{../images/hierarchical/methods_comparison.pdf}
  \caption{Confronto tra diversi metodi}
\end{figure}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\textwidth]{../images/hierarchical/silhouette_average_euclidean_n2.pdf}
  \caption{Confronto tra silhouette medie, per due clusters}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\textwidth]{../images/hierarchical/silhouette_comparison.pdf}
  \caption{Confronto tra silhouette medie, per due clusters}
\end{figure}


