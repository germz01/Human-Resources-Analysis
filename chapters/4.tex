Al fine di costruire un \textit{decision tree} con i record a nostra disposizione, abbiamo eseguito alcune
manipolazioni prima della costruzione dell'albero vero e proprio: sia la variabile \textit{Salary} che la
variabile \textit{Department} sono state convertite in variabili numeriche, per facilitare l'applicazione dell'
algoritmo sui records, inoltre, per fornire un \textit{target} durante la costruzione dell'albero, la variabile
\textit{Left} è stata separata dal data set fornito. Tutte le altre variabili sono state lasciate inalterate.
\section{Learning of different decision trees} % (fold)
\label{sec:learning_of_different_decision_trees}
Durante la fase di costruzione vera e propia, abbiamo deciso di implementare due alberi distinti, differenziandoli
nel modo in cui essi avrebbero dovuto scegliere lo \textit{split} migliore. Abbiamo perciò costruito un albero
basato sull'indice \textit{Gini} come misura di impurità di un nodo, e un albero basato invece sull'uso
dell'\textit{Entropia}. Utilizzando questi due indici di impurità, al momento di decidere quale split
imporre, viene selezionato quello con il \textit{gain} maggiore. Inizialmente abbiamo costruito entrambi gli
alberi senza dare un limite sul numero di samples che un nodo avrebbe dovuto contenere per poter essere
diviso, successivamente però, per evitare di incorrere nel noto fenomeno dell'\textit{overfitting}, abbiamo
voluto esplorare le possibilità date dal consentire uno split a patto che almeno il $10\%$ o il $20\%$ del numero
totale di data objects sia presente nel nodo da dividere. In questa fase iniziale abbiamo utilizzato l'intero
data set come base per il training dell'albero, nelle sezioni successive modificheremo questa assunzione,
dividento i data objects forniti tra test set e training set in percentuali ben definite.
% section learning_of_different_decision_trees (end)
\section{Decision trees interpretation} % (fold)
\label{sec:decision_trees_interpretation}

% section decision_trees_interpretation (end)
\section{Decision trees validation with test and training set} % (fold)
\label{sec:decision_trees_validation_with_test_and_training_set}

% section decision_trees_validation_with_test_and_training_set (end)
\section{Discussion of the best prediction model} % (fold)
\label{sec:discussion_of_the_best_prediction_model}

% section discussion_of_the_best_prediction_model (end)
