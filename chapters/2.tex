\todo[inline]{In generale adotterei un approccio DRY, ovvero eviterei ripetizioni, dicendo ad esempio in questo paragrafo facciamo questo.
  (Modificare anche paragrafi precedenti, inoltre c'è il titolo che indica cosa si fa in ciascun punto). Eviterei di annunciare quello che verrà fatto per poi spiegarlo, spiegare direttamente nel punto giusto}
La ricerca di gruppi di dipendenti con caratteristiche affini all'interno del dataset è stata eseguita utilizzando
differenti tecniche di clustering. Per eseguire l'analisi sono state selezionate solamente le 5 variabili numeriche in Tab. \ref{tab:variabili},
in modo da calcolare le distanze tra i dati in modo appropriato.
Le variabili sono state standardizzate o normalizzate? Decidere spiegare confrontare.
Come già specificato nella Sezione \ref{sec:variable_transformations}, i valori delle variabili discrete sono stati normalizzati in un intervallo
compreso tra $0$ e $1$, al fine di rendere più agevole il confronto in fase di clustering.

\section{Clustering Analysis by K-means} % (fold)
\label{sec:clustering_analysis_by_k_means}
\subsection{Choice of attributes and distance function} % (fold)
\label{sub:choice_of_attributes_and_distance_function}

\todo[inline]{Scelta delle variabili vale per tutte e tre le tecniche, rimuovere da qua.}
Le \textit{variabili} sulle quali abbiamo deciso di applicare l'analisi tramite K-means sono un sottoinsieme di
quelle a disposizione nel data set, in particolare, sono le variabili di tipo continuo
\textit{Satisfaction Level} e \textit{Latest Evaluation}, e le variabili di tipo discreto
\textit{Number Project}, \textit{Average Montly Hours} e \textit{Time Spend Company}. Sono state escluse le
variabili binarie. Vista la natura delle variabili utilizzate nell'applicazione dell'algoritmo, la distance
function da noi utilizzata per quantificare la distanza tra due data objects è la \textit{distanza Euclidea},
rappresentata dalla nota formula
\todo[inline]{Per quanto riguarda le formule o le mettiamo tutte o non ne mettiamo nessuna. Poichè non è richiesta la spiegazione
degli algoritmi e poichè le quantità sono note alle persone che leggono eliminerei TUTTE le formule, concentriamoci sui risultati}

\begin{equation*}
    dist(p,\ q) \ = \ \sqrt{\sum_{i = 0}^{k}(q_i - p_i)^2}\quad,
\end{equation*}
dove con $q_i$ e $p_i$ vengono rappresentati li i-esimi attributi dei data objects $p$ e $q$. Infine, come
ulteriori casi di studio, sono riportate anche le analisi relative alla sola porzione del data set contenente gli
impiegati che hanno lasciato l'azienda e a quella invece contenente gli impiegati ancora al suo interno.
% subsection choice_of_attributes_and_distance_function (end)
\subsection{Identification of the best value of k} % (fold)
\label{sub:identification_of_the_best_value_of_k}
\todo[inline]{eliminare formula SSE, semplicemente SSE, al max va bene lasciare la riga di spiegazione di cos'è}
Al fine di identificare il miglior numero $k$ di clusters da utilizzare, abbiamo tenuto conto dell'
\textit{Error Sum of Squares} (SSE), ossia della somma, elevata al quadrato, della distanza tra ogni singolo data object e il centroide più vicino, ottenuta mediante la formula
\begin{equation*}
    SSE \ = \ \sum_{i = 1}^{K} \sum_{x \in C_i} dist(c_i,\ x)^2 \quad ,
\end{equation*}
dove \textit{dist} rappresenta la distanza Euclidea tra il centroide $c_i$ ed il data object $x$.
 A partire da un valore iniziale di $k$ pari a $2$ fino ad un valore
massimo di $50$ abbiamo calcolato l'SSE risultante dall'applicazione dell'algoritmo come possiamo osservare in
Figura \ref{fig:sse}, e abbiamo infine deciso per un valore di $k$ pari a $4$ per l'applicazione di K-means sul
data set totale, in quanto ritenuto il valore più efficiente ai fini della nostra analisi. Tale valore è stato poi
confermato come il più elevato tra quelli osservati tramite lo studio del \textit{Silhouette score}.
% subsection identification_of_the_best_value_of_k (end)
\todo[inline]{Perchè abbiamo deciso 4 dal grafico? Commentare/spiegare. Quanto vale la silhouette score???
  Le spiegazioni non devono andare a fiducia, dobbiamo mostrare i dati risultanti e commentarli oggettivamente.
  Il grafico lo farei su una scala inferiore: visto che siamo interessati a un numero basso di cluster, metterei  ad esempio un numero max di cluster=20  o altro valore in modo da vedere bene le variazioni nella nostra zona di interesse. (Poi nella spiegazione puoi dire che abbiamo fatto fino a 50, insomma il grafico deve essere zoommato) Sennò puoi metterne due affiancati, uno con l'andamento generale ed uno zoommato.}

\subsection{Characterization of the obtained clusters } % (fold)
\label{sub:characterization_of_the_obtained_clusters}
In quest'ultima sezione relativa all'algoritmo K-means descriviamo i clusters emersi durante l'analisi.
Utilizzando i parametri descritti nelle sezioni precedenti, abbiamo ottenuto i clusters raffigurati in Figura
\ref{fig:dist_clu}, dove possiamo osservare la densità di popolazione per ognuno dei cluster ottenuti.
In Tabella \ref{tab:stat_descr} abbiamo riportato i dati caratteristici di ognuno dei cluster scoperti.
Il primo cluster emerso, Cluster $0$ contraddistingue gli impiegati con un alto score nelle variabili
Last Evaluation e Satisfaction Level. Possiamo pensare a un tale cluster come a un gruppo di impiegati molto
soddisfatti e valutati positivamente, da poco assunti, visto lo score basso in Time Spend Company. Il secondo
Cluster, Cluster $1$, presenta un gruppo di impiegati con uno score basso nelle variabili Average Montly
Hours e Satisfaction Level. Tale cluster, essendo il terzo cluster per densità di popolazione, denota un risultato
interessante e sicuramente da tenere d'occhio per i futuri sviluppi dell'azienda.
Il Cluster $2$ presenta un gruppo di impiegati soddisfatti e produttivi, con carichi di lavoro abbastanza elevati.
L'ultimo cluster, il $3$, presenta una situazione preoccupante, visto gli score molto elevati degli impiegati
nelle variabili Average Montly Hours, Last Evaluation e Number Project, e il basso score nella variabile
Satisfaction Level. Vedendo simili risultati è facile immaginarsi un gruppo di impiegati da poco assunti,
caratterizzati da un alto tasso di ore di lavoro, il quale ha comportato il calo nel livello di soddisfazione,
nonostante l'ultima valutazione fosse stata più che positiva.

\todo[inline]{Per la caratterizzazione dei clusters serve un qualche grafico che esprima quello che hai detto a parole
  nei commenti in modo immediato. Le tabelle sono utili come riferimento,
  ma andarsi a leggere sulle tabelle cosa sta succedendo non è nè immediato nè piacevole. (i valori devono essere arrotondati). 
  Una possibilità per fare una rappresentazione sintetica è quella di fare un grafico a coordinate parallele, con sulle x le labels dei cluster e sulle y i relativi valori delle variabili, una linea per ciascuna variabile. Non so se l'ho spiegato bene, se vuoi posso provare a farlo, dimmi te.
Sennò altre idee?}



\begin{figure}[t!]
  \centering
  \begin{subfigure}{0.5\textwidth}
    \resizebox{\textwidth}{!}{
      \includegraphics{images/kmeans/SSE.pdf}
    }
    \caption{Sviluppo dell'SSE in base all'aumentare del numero di clusters nell'applicazione dell'algoritmo
    K-means.}
    \label{fig:sse}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    \resizebox{\textwidth}{!}{
      \includegraphics[width=0.5\textwidth]{images/kmeans/dist_cluster.pdf}
    }
    \caption{Distribuzione del numero di impiegati per ognuno dei cluster scoperti durante l'analisi, in ordine
    decrescente per densità di popolazione.}
    \label{fig:dist_clu}
  \end{subfigure}
\end{figure}
\begin{table}[H]
  \centering
  \begin{subtable}{0.4\textwidth}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{| c | c | c | c | c | c |}
    \hline
    {} & \multicolumn{5}{c |}{Average\_Montly\_Hours} \\
    \hline
    {} & count & mean & std & min & max \\
    Cluster & & & & &  \\
    \hline
    0 & 4718.0 & 0.335402713014 & 0.119339203198 & 0.0 & 0.57 \\
    1 & 3112.0 & 0.266349614396 & 0.131965498666 & 0.0 & 0.88 \\
    2 & 5343.0 & 0.687986150103 & 0.0978323000066 & 0.32 & 1.0 \\
    3 & 1826.0 & 0.698707557503 & 0.218737034635 & 0.01 & 1.0 \\
    \hline
    \end{tabular}
  }
  \caption{}
  \label{tab:dist_Average_Montly_Hours}
  \end{subtable}
  \begin{subtable}{0.4\textwidth}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{| c | c | c | c | c | c |}
    \hline
    {} & \multicolumn{5}{c |}{Last\_Evaluation} \\
    \hline
    {} & count & mean & std & min & max \\
    Cluster & & & & &  \\
    \hline
    0 & 4718.0 & 0.72940652819 & 0.154968000745 & 0.36 & 1.0 \\
    1 & 3112.0 & 0.556725578406 & 0.117328197911 & 0.36 & 1.0 \\
    2 & 5343.0 & 0.769792251544 & 0.159907000653 & 0.36 & 1.0 \\
    3 & 1826.0 & 0.796243154436 & 0.147510906101 & 0.36 & 1.0 \\
    \hline
    \end{tabular}
  }
  \caption{}
  \label{tab:dist_Last_Evaluation}
  \end{subtable}
  \begin{subtable}{0.4\textwidth}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{| c | c | c | c | c | c |}
    \hline
    {} & \multicolumn{5}{c |}{Number\_Project} \\
    \hline
    {} & count & mean & std & min & max \\
    Cluster & & & & &  \\
    \hline
    0 & 4718.0 & 0.373251377702 & 0.171899268358 & 0.0 & 1.0 \\
    1 & 3112.0 & 0.087146529563 & 0.133356468399 & 0.0 & 0.8 \\
    2 & 5343.0 & 0.382481751825 & 0.177865527878 & 0.0 & 0.8 \\
    3 & 1826.0 & 0.730010952903 & 0.185110703318 & 0.0 & 1.0 \\
    \hline
    \end{tabular}
  }
  \caption{}
  \label{tab:dist_Number_Project}
  \end{subtable}
  \begin{subtable}{0.4\textwidth}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{| c | c | c | c | c | c |}
    \hline
    {} & \multicolumn{5}{c |}{Satisfaction\_Level} \\
    \hline
    {} & count & mean & std & min & max \\
    Cluster & & & & &  \\
    \hline
    0 & 4718.0 & 0.753912674862 & 0.149069029588 & 0.29 & 1.0 \\
    1 & 3112.0 & 0.426690231362 & 0.113426667634 & 0.09 & 0.96 \\
    2 & 5343.0 & 0.746524424481 & 0.146280707568 & 0.25 & 1.0 \\
    3 & 1826.0 & 0.174364731654 & 0.103883794638 & 0.09 & 0.63 \\
    \hline
    \end{tabular}
  }
  \caption{}
  \label{tab:dist_Satisfaction_Level}
  \end{subtable}
  \begin{subtable}{0.4\textwidth}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{| c | c | c | c | c | c |}
    \hline
    {} & \multicolumn{5}{c |}{Time\_Spend\_Company} \\
    \hline
    {} & count & mean & std & min & max \\
    Cluster & & & & &  \\
    \hline
    0 & 4718.0 & 0.135247986435 & 0.151055406452 & 0.0 & 1.0 \\
    1 & 3112.0 & 0.165690874036 & 0.152454170381 & 0.0 & 1.0 \\
    2 & 5343.0 & 0.216769605091 & 0.212362864942 & 0.0 & 1.0 \\
    3 & 1826.0 & 0.294408543264 & 0.14565978606 & 0.0 & 1.0 \\
    \hline
    \end{tabular}
  }
  \caption{}
  \label{tab:dist_Time_Spend_Company}
  \end{subtable}
  \caption{Statistica descrittiva relativa ad ognuno dei cluster scoperti. Per ogni cluster vengono riportate le
  informazioni relative alla densità di popolazione, alla media, alla deviazione standard e ai valori minimi e
  massimi delle variabili utilizzate.}
  \label{tab:stat_descr}
  \end{table}
\begin{figure}[h!]
  \centering
  \begin{subfigure}{0.45\textwidth}
    \centering
    \resizebox{\textwidth}{!}{
      \includegraphics{images/kmeans/cluster_left.pdf}
    }
    \caption{}
    \label{fig:cluster_left}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
    \centering
    \resizebox{\textwidth}{!}{
      \includegraphics{images/kmeans/cluster_stayed.pdf}
    }
    \caption{}
    \label{fig:cluster_stayed}
  \end{subfigure}
  \caption{Visualizzazione relativa all'applicazione dell'algoritmo K-means sul data set diviso in funzione della
  variabile \textit{Left}. In Figura \ref{fig:cluster_left} è possibile osservare il clustering relativo agli
  impiegati che hanno lasciato l'azienda, mentre in Figura \ref{fig:cluster_stayed} troviamo il clustering
  relativo agli impiegati che sono rimasti. L'analisi dell'SSE e dello score della silhouette ha rivelato che,
  applicando l'algoritmo soltanto sulle variabili Satisfaction Level e Last Evaluation, il numero ideale di
  clusters è $3$ per gli impiegati che hanno lasciato l'azienda, e $5$ per gli altri.}
  \label{fig:cluster_splitted}
\end{figure}
\newpage
Come ulteriore esempio, in Figura \ref{fig:cluster_splitted} forniamo le visualizzazioni relative all'applicazione
di K-means, utilizzando le variabili Satisfaction Level e Last Evaluation, al data set diviso in base alla
variabile Left. Similmente a quanto fatto per l'algoritmo applicato all'intero data set, abbiamo prima studiato
l'SSE, e confrontato le nostre ipotesi con lo score fornito dall'analisi della silhouette. Come possiamo vedere
nella Figura \ref{fig:cluster_left},
i $3$ clusters emersi per gli impiegati che hanno lasciato l'azienda delineano un gruppo di impiegati con un basso
score sia in Satisfaction Level che in Last Evaluation, un gruppo con un alto score in Last Evaluation e un basso
score in Satisfaction Level e un gruppo con alto score in entrambe le variabili. Per gli impiegati ancora
all'interno dell'azienda, possiamo notare nella Figura \ref{fig:cluster_stayed} che la situazione è decisamente
più distribuita.
\section{Hierarchical clustering}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{../images/hierarchical/dendrogram_average_euclidean.pdf}
  \caption{Dendrogramma per method X e metrica Y}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\textwidth]{../images/hierarchical/methods_comparison.pdf}
  \caption{Confronto tra diversi metodi}
\end{figure}


\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\textwidth]{../images/hierarchical/silhouette_average_euclidean_n2.pdf}
  \caption{Confronto tra silhouette medie, per due clusters}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.7\textwidth]{../images/hierarchical/silhouette_comparison.pdf}
  \caption{Confronto tra silhouette medie, per due clusters}
\end{figure}


